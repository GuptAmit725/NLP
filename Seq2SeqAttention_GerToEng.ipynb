{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_GerToEng.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyODKI1p8LHqf72MGndUeui2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuptAmit725/NLP/blob/main/Seq2SeqAttention_GerToEng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpHxBDPUeUBn"
      },
      "source": [
        "<h1><I>Installling necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgQi9g3TIxPB"
      },
      "source": [
        "!pip install torchtext==0.6.0\n",
        "!pip install -U spacy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_2Fn9V3Jf8d"
      },
      "source": [
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gald9ifzeZqB"
      },
      "source": [
        "<h1><I>Importing necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KUg8nocbgZFL",
        "outputId": "bfb95b74-94e4-41dd-acd3-3e95bda3e881"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "import numpy as np\n",
        "import spacy as sp\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import UTILS, UTILS_ATT\n",
        "nltk.download('punkt')\n",
        "from torch.utils.tensorboard import SummaryWriter "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZNOzjUHehJd"
      },
      "source": [
        "<h1><I>Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37_HUqVE8wkw"
      },
      "source": [
        "import spacy\n",
        "spacy_eng = sp.load(\"en_core_web_sm\")\n",
        "spacy_ger = spacy.load(\"de_core_news_sm\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZYrAzyaeqPu"
      },
      "source": [
        "<h1><I>Tokenizing the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQvDNk63HJdH"
      },
      "source": [
        "def tokenize_ger(text):\n",
        "  return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
        "\n",
        "def tokenize_eng(text):\n",
        "  return [tok.text for tok in spacy_eng.tokenizer(text)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CNA0CYxL0I7"
      },
      "source": [
        "german = Field(tokenize=tokenize_ger, lower=True, init_token='<sos>', eos_token='<eos>')\n",
        "english = Field(tokenize=tokenize_eng, lower=True, init_token='<sos>', eos_token='<eos>')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0_I-Evbew6n"
      },
      "source": [
        "<h1><I>Splitting the data into train, validation and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yyZ9PTdiMWKz",
        "outputId": "7944962f-9092-43b9-8030-8cc23cd07407"
      },
      "source": [
        "train_data, validation_data, test_data = Multi30k.splits( exts=('.de', '.en'), fields=(german,english))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:02<00:00, 595kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 169kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 166kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WMxro0_qM0C0",
        "outputId": "cceb6cb5-682e-4c61-a69c-cc618a38dd69"
      },
      "source": [
        "type(spacy_eng)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.lang.en.English"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX0oc_GOe4GC"
      },
      "source": [
        "<h1><I>Building the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymwRBDjxM9Og"
      },
      "source": [
        "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmARRAPEe9qS"
      },
      "source": [
        "<h1><I>CReating the classes of Encoder and decoder and creating model out of it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6yjeRqkfIAb"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, \n",
        "               hidden_size,num_layers,d_rate):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.dropout = nn.Dropout(d_rate)\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional = True)\n",
        "    self.fc_hidden = nn.Linear(hidden_size*2, hidden_size)\n",
        "    self.fc_cell = nn.Linear(hidden_size*2,hidden_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    x = self.dropout(x)\n",
        "    output, (hidden,cell) = self.lstm(x)\n",
        "    hidden = self.fc_hidden(torch.cat((hidden[0:1],hidden[1:2]),dim=2))\n",
        "    cell = self.fc_cell(torch.cat((cell[0:1],cell[1:2]),dim=2))\n",
        "    return output,hidden, cell\n",
        "\n",
        "class selfAttention(nn.Module):\n",
        "  def __init__(self,hidden_size):\n",
        "    super(selfAttention,self).__init__()\n",
        "    self.energy = nn.Linear(hidden_size*3,1)\n",
        "    self.softmax = nn.Softmax(dim=0)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self,hidden,enc_output):\n",
        "    energy = self.relu(self.energy(torch.cat((hidden,enc_output),dim=2)))\n",
        "    attention = self.softmax(energy) #(sequence_length,N,1) \n",
        "    context_vector = torch.einsum(\"snk,snl->knl\",attention,enc_output) #(N,1,hidden_size*2)\n",
        "\n",
        "    return context_vector\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self,input_size, \n",
        "               embedding_size, \n",
        "               hidden_size, \n",
        "               output_size, \n",
        "               num_layers, d_rate\n",
        "               ):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    self.dropout = nn.Dropout(d_rate)\n",
        "    self.lstm = nn.LSTM(hidden_size*2 + embedding_size, hidden_size,num_layers)# removing dropout as we have only one layer.\n",
        "    self.fc = nn.Linear(hidden_size,output_size)\n",
        "    self.Attention = selfAttention(hidden_size)\n",
        "\n",
        "  def forward(self,x,encoder_output, hidden, cell):\n",
        "    x = x.unsqueeze(0)\n",
        "    x = self.embedding(x)\n",
        "    x = self.dropout(x) #(1,N,embedding_size)\n",
        "\n",
        "    sequence_length = encoder_output.shape[0]\n",
        "    hidden_reshaped = hidden.repeat(sequence_length,1,1)\n",
        "    context_vector = self.Attention(hidden_reshaped,encoder_output)\n",
        "    output, (hidden, cell) = self.lstm(torch.cat((context_vector,x),dim=2),(hidden,cell))\n",
        "    pred = self.fc(output).squeeze(0)\n",
        "\n",
        "    return pred, hidden, cell\n",
        "\n",
        "class model(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super(model,self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, src, trg, teacher_force_ratio=0.5):\n",
        "    batch_size = src.shape[1]\n",
        "    target_len = trg.shape[0]\n",
        "    target_vocab_size = len(english.vocab)\n",
        "\n",
        "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "    # Since we are doing word by word prediction\n",
        "\n",
        "    encoder_output,hidden, cell = self.encoder(src)\n",
        "\n",
        "    #grabing start token\n",
        "    x = trg[0]\n",
        "\n",
        "    for t in range(1,target_len):\n",
        "      output, hidden, cell = self.decoder(x,encoder_output,hidden, cell)\n",
        "      outputs[t] = output\n",
        "      best_guess = output.argmax(1)\n",
        "      x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
        "      # In this line we are feeding actual target value and output of the previous decoder alternatively.\n",
        "    return outputs\n",
        "\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvalF279fIry"
      },
      "source": [
        "<h1><I>Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJF_nEqIVKae"
      },
      "source": [
        "!mkdir 'ckpt'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OYcwSESdcaM"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model_.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for i, batch in enumerate(iterator):\n",
        "            \n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "            \n",
        "            output = model(src, trg, 0) # turn off teacher forcing.\n",
        "            \n",
        "            # trg = [sen_len, batch_size]\n",
        "            # output = [sen_len, batch_size, output_dim]\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            \n",
        "    return epoch_loss / len(iterator)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4BEcgCEffmI6",
        "outputId": "bef915cf-5f2a-4857-9922-92dca03d3c57"
      },
      "source": [
        "import math\n",
        "#training hyper parameters\n",
        "epochs = 10\n",
        "lr = 0.001\n",
        "batch_size = 64\n",
        "\n",
        "#Model hyperparameters\n",
        "load_model = False\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "input_size_enc = len(german.vocab)\n",
        "input_size_dec = len(english.vocab)\n",
        "output_size = len(english.vocab)\n",
        "encoder_embedding_size = 300\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 1024\n",
        "num_layers = 1\n",
        "enc_droput = 0.5\n",
        "dec_dropout = 0.5\n",
        "#tensorboard\n",
        "\n",
        "writer = SummaryWriter(f'runs/loss_plot')\n",
        "step = 0\n",
        "loss = 0\n",
        "validation_loss = 0\n",
        "best_validation_loss = float('inf')\n",
        "pad_idx = english.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, validation_data, test_data),\n",
        "    batch_size = batch_size,\n",
        "    sort_within_batch = True,\n",
        "    sort_key = lambda x: len(x.src),\n",
        "    device = device\n",
        ")\n",
        "\n",
        "enc_net = Encoder(input_size_enc,\n",
        "                  encoder_embedding_size, \n",
        "                  hidden_size, num_layers,\n",
        "                  dec_dropout).to(device)\n",
        "\n",
        "dec_net = Decoder(input_size_dec, \n",
        "                  decoder_embedding_size,\n",
        "                  hidden_size, output_size,\n",
        "                  num_layers, dec_dropout\n",
        "                  ).to(device)\n",
        "\n",
        "\n",
        "model_ = model(enc_net, dec_net).to(device)\n",
        "optimizer = torch.optim.Adam(model_.parameters(),lr = lr)\n",
        "sent = \"Ich komme zu hause.\"\n",
        "if load_model:\n",
        "  load_checkpoint(torch.load('my_checkpoint.pth.ptar'), model_, optimizer)\n",
        "\n",
        "for epoch in range(epochs): \n",
        "  print(f'Epoch [{epoch} / {epochs}]')\n",
        "  checkpoint = {\"state_dict\": model_.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
        "  UTILS.save_checkpoint(checkpoint) \n",
        "  model_.eval()\n",
        "  tr_sent = UTILS_ATT.translate_sentence(model_,sent,german, english,device)\n",
        "  print(\" \".join(tr_sent))\n",
        "  model_.train()\n",
        "  for batch_idx, batch in enumerate(train_iterator):\n",
        "    inp_data = batch.src.to(device)\n",
        "    target = batch.trg.to(device)\n",
        "    #print('INP SHAPE ===== ', inp_data.shape, target.shape)\n",
        "    output = model_(inp_data, target)\n",
        "\n",
        "    output = output[1:].reshape(-1, output.shape[2])\n",
        "    target = target[1:].reshape(-1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model_.parameters(), max_norm = 1)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    writer.add_scalar('Training Loss', loss, global_step=step)\n",
        "    #print('TRAINING LOSS ====', loss)\n",
        "    step += 1\n",
        "\n",
        "\n",
        "  validation_loss = evaluate(model_,valid_iterator, criterion) \n",
        "  if validation_loss < best_validation_loss:\n",
        "      best_validation_loss = validation_loss\n",
        "      torch.save(model_.state_dict(), 'ckpt/Seq2SeqModel.pt')\n",
        "  #print(f\"Epoch: {epoch+1:02} | Time {epoch_mins}m {epoch_secs}s\")\n",
        "  print(f\"\\tTrain Loss: {loss:.3f} | Train PPL: {math.exp(loss):7.3f}\")\n",
        "  print(f\"\\tValid Loss: {validation_loss:.3f} | Valid PPL: {math.exp(validation_loss):7.3f}\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0 / 10]\n",
            "=> Saving checkpoint\n",
            "strewn volcano headset boy travel travel travel travel lot mark engine hollister situation charcoal tree cereal brindle whatever consults spending leafless that furniture merchandise furniture merchandise furniture merchandise furniture merchandise furniture merchandise furniture merchandise furniture merchandise furniture merchandise furniture merchandise furniture merchandise furniture merchandise furniture merchandise furniture merchandise furniture merchandise\n",
            "\tTrain Loss: 3.221 | Train PPL:  25.064\n",
            "\tValid Loss: 3.954 | Valid PPL:  52.122\n",
            "Epoch [1 / 10]\n",
            "=> Saving checkpoint\n",
            "<unk> are to to a . . <eos>\n",
            "\tTrain Loss: 2.463 | Train PPL:  11.736\n",
            "\tValid Loss: 3.709 | Valid PPL:  40.803\n",
            "Epoch [2 / 10]\n",
            "=> Saving checkpoint\n",
            "construction workers are preparing to . <eos>\n",
            "\tTrain Loss: 2.693 | Train PPL:  14.780\n",
            "\tValid Loss: 3.609 | Valid PPL:  36.916\n",
            "Epoch [3 / 10]\n",
            "=> Saving checkpoint\n",
            "a workers are preparing to be . <eos>\n",
            "\tTrain Loss: 2.888 | Train PPL:  17.966\n",
            "\tValid Loss: 3.514 | Valid PPL:  33.597\n",
            "Epoch [4 / 10]\n",
            "=> Saving checkpoint\n",
            "visitors workers to to to use . <eos>\n",
            "\tTrain Loss: 2.633 | Train PPL:  13.917\n",
            "\tValid Loss: 3.485 | Valid PPL:  32.633\n",
            "Epoch [5 / 10]\n",
            "=> Saving checkpoint\n",
            "protesters think to to be to start . <eos>\n",
            "\tTrain Loss: 2.132 | Train PPL:   8.434\n",
            "\tValid Loss: 3.497 | Valid PPL:  33.032\n",
            "Epoch [6 / 10]\n",
            "=> Saving checkpoint\n",
            "protesters <unk> help help help . <eos>\n",
            "\tTrain Loss: 2.951 | Train PPL:  19.131\n",
            "\tValid Loss: 3.517 | Valid PPL:  33.687\n",
            "Epoch [7 / 10]\n",
            "=> Saving checkpoint\n",
            "protesters 's to be <unk> . . <eos>\n",
            "\tTrain Loss: 1.408 | Train PPL:   4.089\n",
            "\tValid Loss: 3.554 | Valid PPL:  34.937\n",
            "Epoch [8 / 10]\n",
            "=> Saving checkpoint\n",
            "hot think help help to start . <eos>\n",
            "\tTrain Loss: 1.209 | Train PPL:   3.349\n",
            "\tValid Loss: 3.590 | Valid PPL:  36.251\n",
            "Epoch [9 / 10]\n",
            "=> Saving checkpoint\n",
            "<unk> workers to to <unk> . <eos>\n",
            "\tTrain Loss: 1.953 | Train PPL:   7.051\n",
            "\tValid Loss: 3.630 | Valid PPL:  37.725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nFR6YPacSloi",
        "outputId": "237a402f-0150-4a3b-df10-36e9857b4400"
      },
      "source": [
        "def test():\n",
        "  best_model = model(enc_net, dec_net).to(device)\n",
        "  best_model.load_state_dict(torch.load('ckpt/Seq2SeqModel.pt'))\n",
        "  \n",
        "  test_loss = evaluate(best_model, test_iterator, criterion)\n",
        "  \n",
        "  print(f\"Test Loss : {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f}\")\n",
        "  return best_model\n",
        "    \n",
        "best_model = test()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss : 3.469 | Test PPL:  32.114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-ewCHj9GfBe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}